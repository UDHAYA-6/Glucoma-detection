{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import ZeroPadding2D, BatchNormalization\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "orginal_image = \"E:\\Saaswath\\optical glcoma\\SOURCE CODE\\dataset\\Glaucomatous\"\n",
    "glauucoma = os.listdir(orginal_image)\n",
    "\n",
    "for i in glauucoma:\n",
    "    orginal = cv2.imread(orginal_image + '/' +i)\n",
    "    cv2.imshow('Orginal',orginal)\n",
    "\n",
    "    mask = np.zeros(orginal.shape[:2],dtype=\"uint8\")\n",
    "    cv2.circle(mask,(145,200),100,255,-1)\n",
    "    \n",
    "\n",
    "    masked = cv2.bitwise_or(orginal,orginal,mask=mask)\n",
    "    cv2.imshow(\"Mask Applied\",masked)\n",
    "    if cv2.waitKey(0) or ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 100, 100, 64)      15616     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 100, 100, 64)     256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100, 100, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 50, 50, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 50, 50, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 50, 50, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 50, 50, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 25, 25, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " zero_padding2d (ZeroPadding  (None, 27, 27, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 27, 27, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 27, 27, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 27, 27, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 13, 13, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " zero_padding2d_1 (ZeroPaddi  (None, 15, 15, 256)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 15, 15, 512)       1180160   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 15, 15, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 15, 15, 512)       0         \n",
      "                                                                 \n",
      " zero_padding2d_2 (ZeroPaddi  (None, 17, 17, 512)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 17, 17, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 17, 17, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 17, 17, 512)       0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 8, 8, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                2097216   \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 1)                4         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,168,005\n",
      "Trainable params: 6,164,675\n",
      "Non-trainable params: 3,330\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = Sequential()\n",
    "\n",
    "base_model.add(Conv2D(64, (9, 9), input_shape=(100, 100, 3), padding='same'))\n",
    "base_model.add(BatchNormalization())\n",
    "base_model.add(Activation('relu'))\n",
    "base_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "base_model.add(Conv2D(128, (5, 5), padding='same'))\n",
    "base_model.add(BatchNormalization())\n",
    "base_model.add(Activation('relu'))\n",
    "base_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "base_model.add(ZeroPadding2D((1, 1)))\n",
    "base_model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "base_model.add(BatchNormalization())\n",
    "base_model.add(Activation('relu'))\n",
    "base_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "base_model.add(ZeroPadding2D((1, 1)))\n",
    "base_model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "base_model.add(BatchNormalization())\n",
    "base_model.add(Activation('relu'))\n",
    "\n",
    "base_model.add(ZeroPadding2D((1, 1)))\n",
    "base_model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "base_model.add(BatchNormalization())\n",
    "base_model.add(Activation('relu'))\n",
    "base_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "base_model.add(Flatten())\n",
    "base_model.add(Dense(64))\n",
    "base_model.add(BatchNormalization())\n",
    "base_model.add(Activation('relu'))\n",
    "base_model.add(Dropout(0.5))\n",
    "\n",
    "base_model.add(Dense(128))\n",
    "base_model.add(BatchNormalization())\n",
    "base_model.add(Activation('relu'))\n",
    "base_model.add(Dropout(0.5))\n",
    "\n",
    "base_model.add(Dense(1))\n",
    "base_model.add(BatchNormalization())\n",
    "base_model.add(Activation('sigmoid'))\n",
    "\n",
    "base_model.compile(loss='binary_crossentropy',\n",
    "                   optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 184 images belonging to 2 classes.\n",
      "Found 184 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=30,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=[0.8, 1.2],\n",
    "                                   horizontal_flip=True,\n",
    "                                   #                                     vertical_flip = True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('./dataset',\n",
    "                                                 target_size=(100, 100),\n",
    "                                                 batch_size=64,\n",
    "                                                 class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('./dataset',\n",
    "                                            target_size=(100, 100),\n",
    "                                            batch_size=64,\n",
    "                                            class_mode='binary')\n",
    "my_callbacks = [\n",
    "    # tf.keras.callbacks.EarlyStopping(patience=4, verbose=1),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        factor=0.1, patience=3, min_lr=0.00001, verbose=1),\n",
    "    tf.keras.callbacks.ModelCheckpoint('my_model2.h5',\n",
    "                                       verbose=1, save_best_only=True, save_weights_only=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6576 - accuracy: 0.6413 \n",
      "Epoch 1: val_loss improved from inf to 0.68659, saving model to my_model2.h5\n",
      "3/3 [==============================] - 44s 15s/step - loss: 0.6576 - accuracy: 0.6413 - val_loss: 0.6866 - val_accuracy: 0.5054 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6077 - accuracy: 0.6359\n",
      "Epoch 2: val_loss did not improve from 0.68659\n",
      "3/3 [==============================] - 40s 15s/step - loss: 0.6077 - accuracy: 0.6359 - val_loss: 0.7382 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6368 - accuracy: 0.6848 \n",
      "Epoch 3: val_loss did not improve from 0.68659\n",
      "3/3 [==============================] - 42s 15s/step - loss: 0.6368 - accuracy: 0.6848 - val_loss: 0.8250 - val_accuracy: 0.5109 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5540 - accuracy: 0.7554 \n",
      "Epoch 4: val_loss improved from 0.68659 to 0.65471, saving model to my_model2.h5\n",
      "3/3 [==============================] - 42s 16s/step - loss: 0.5540 - accuracy: 0.7554 - val_loss: 0.6547 - val_accuracy: 0.6087 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5168 - accuracy: 0.7337 \n",
      "Epoch 5: val_loss improved from 0.65471 to 0.59756, saving model to my_model2.h5\n",
      "3/3 [==============================] - 41s 15s/step - loss: 0.5168 - accuracy: 0.7337 - val_loss: 0.5976 - val_accuracy: 0.6957 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5285 - accuracy: 0.7500 \n",
      "Epoch 6: val_loss did not improve from 0.59756\n",
      "3/3 [==============================] - 46s 16s/step - loss: 0.5285 - accuracy: 0.7500 - val_loss: 0.6624 - val_accuracy: 0.5815 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5025 - accuracy: 0.7663 \n",
      "Epoch 7: val_loss did not improve from 0.59756\n",
      "3/3 [==============================] - 43s 16s/step - loss: 0.5025 - accuracy: 0.7663 - val_loss: 0.7337 - val_accuracy: 0.5054 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4934 - accuracy: 0.7772 \n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.59756\n",
      "3/3 [==============================] - 42s 15s/step - loss: 0.4934 - accuracy: 0.7772 - val_loss: 0.8449 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5132 - accuracy: 0.7772 \n",
      "Epoch 9: val_loss did not improve from 0.59756\n",
      "3/3 [==============================] - 42s 16s/step - loss: 0.5132 - accuracy: 0.7772 - val_loss: 0.7652 - val_accuracy: 0.4946 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5109 - accuracy: 0.7717 \n",
      "Epoch 10: val_loss did not improve from 0.59756\n",
      "3/3 [==============================] - 40s 15s/step - loss: 0.5109 - accuracy: 0.7717 - val_loss: 0.7123 - val_accuracy: 0.4891 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5068 - accuracy: 0.7989 \n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.59756\n",
      "3/3 [==============================] - 40s 14s/step - loss: 0.5068 - accuracy: 0.7989 - val_loss: 0.6723 - val_accuracy: 0.5435 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5061 - accuracy: 0.7717 \n",
      "Epoch 12: val_loss did not improve from 0.59756\n",
      "3/3 [==============================] - 40s 15s/step - loss: 0.5061 - accuracy: 0.7717 - val_loss: 0.6505 - val_accuracy: 0.6087 - lr: 1.0000e-05\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4912 - accuracy: 0.8152 \n",
      "Epoch 13: val_loss did not improve from 0.59756\n",
      "3/3 [==============================] - 42s 16s/step - loss: 0.4912 - accuracy: 0.8152 - val_loss: 0.6407 - val_accuracy: 0.6467 - lr: 1.0000e-05\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4887 - accuracy: 0.7989 \n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.59756\n",
      "3/3 [==============================] - 42s 16s/step - loss: 0.4887 - accuracy: 0.7989 - val_loss: 0.6395 - val_accuracy: 0.6522 - lr: 1.0000e-05\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5038 - accuracy: 0.7717 \n",
      "Epoch 15: val_loss did not improve from 0.59756\n",
      "3/3 [==============================] - 42s 16s/step - loss: 0.5038 - accuracy: 0.7717 - val_loss: 0.6401 - val_accuracy: 0.5978 - lr: 1.0000e-05\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5034 - accuracy: 0.8207\n",
      "Epoch 16: val_loss did not improve from 0.59756\n",
      "3/3 [==============================] - 40s 14s/step - loss: 0.5034 - accuracy: 0.8207 - val_loss: 0.6424 - val_accuracy: 0.5924 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4948 - accuracy: 0.8152 \n",
      "Epoch 17: val_loss did not improve from 0.59756\n",
      "3/3 [==============================] - 43s 16s/step - loss: 0.4948 - accuracy: 0.8152 - val_loss: 0.6446 - val_accuracy: 0.5652 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5008 - accuracy: 0.7717\n",
      "Epoch 18: val_loss did not improve from 0.59756\n",
      "3/3 [==============================] - 40s 14s/step - loss: 0.5008 - accuracy: 0.7717 - val_loss: 0.6477 - val_accuracy: 0.5489 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5005 - accuracy: 0.7554\n",
      "Epoch 19: val_loss did not improve from 0.59756\n",
      "3/3 [==============================] - 40s 14s/step - loss: 0.5005 - accuracy: 0.7554 - val_loss: 0.6498 - val_accuracy: 0.5435 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4820 - accuracy: 0.7989 \n",
      "Epoch 20: val_loss did not improve from 0.59756\n",
      "3/3 [==============================] - 40s 14s/step - loss: 0.4820 - accuracy: 0.7989 - val_loss: 0.6498 - val_accuracy: 0.5435 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d1ae6253c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.fit(training_set, epochs=20,\n",
    "               validation_data=test_set, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002D1B10DD750> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002D1B10DDA20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "data = pd.DataFrame()\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    model = Model(inputs=base_model.input,outputs=base_model.get_layer(layer.name).output)\n",
    "    img_path = r'E:\\Saaswath\\optical glcoma\\SOURCE CODE\\dataset\\Glaucomatous\\glaucoma_389.jpg'\n",
    "    img = image.load_img(img_path,target_size=(100,100))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x,axis=0)\n",
    "    pred = model.predict(x)\n",
    "    reshape = np.reshape(pred, (-1))\n",
    "    data[\"feature\"] = pd.Series(reshape)\n",
    "    data.to_csv(\"feature_extraction1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34398e71c613feb1c5fcf314f4af4e3ee84bb45f672ac17f2633b52ef55a12ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
